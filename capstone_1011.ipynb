{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capstone_1011.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choisanghoon/bme-haha/blob/main/capstone_1011.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfGXYSRwBgBS"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib.pyplot import imshow \n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxXe2QI7BoKU"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6efQy4iE4Hd7",
        "outputId": "6cd19280-dd15-4cee-ee74-19824a147805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEL6xn-w4DNB"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from matplotlib.pyplot import imshow \n",
        "# 이미지를 보여주기 위한 function을 불러옴\n",
        "%matplotlib inline \n",
        "# matplotlib의 출력값이 노트북 상에 출력되게 함\n",
        "# 불러온 이미지 파일이 Python 이미지 라이브러리를 통해 불러와지기 때문에 노트북 상에 표시되게 하기 위함\n",
        "\n",
        "\n",
        "trans = transforms.Compose([\n",
        "  transforms.Resize((224,224))                            \n",
        "])\n",
        "# torchvision의 transforms.Compose라는 function, transform을 많이 수행해야될 때 일일히 아래에 넣어주기 번거로워 하나로 묶어주는 역할\n",
        "\n",
        "trans_data = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/data set/chest_xray/train', transform=trans)\n",
        "\n",
        "for num, value in enumerate(trans_data):\n",
        "  data, label = value\n",
        "  print(num, data, label)\n",
        "\n",
        "  if (label == 0):\n",
        "    data.save('drive/My Drive/Resize_train/NORMAL/%d_%d.jpeg'%(num, label))\n",
        "  else:\n",
        "    data.save('drive/My Drive/Resize_train/PNEUMONIA/%d_%d.jpeg'%(num, label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ATgzejCbFn",
        "outputId": "bb5a0cc2-295a-48af-87aa-f56d4cd1c0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline \n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()                             \n",
        "])\n",
        "trainset = torchvision.datasets.ImageFolder(root='drive/My Drive/Resize_train', transform=transform)\n",
        "print(trainset)\n",
        "\n",
        "train_data_mean = torch.Tensor([0.5, 0.5, 0.5])\n",
        "train_data_std = torch.Tensor([0.5, 0.5, 0.5])\n",
        "#train_data_mean = trainset.data.mean(axis=(0,1,2))\n",
        "#train_data_std  = trainset.data.std(axis=(0,1,2))\n",
        "\n",
        "print(train_data_mean)\n",
        "print(train_data_std)\n",
        "\n",
        "#train_data_mean = train_data_mean / 255\n",
        "#train_data_std  = train_data_std / 255\n",
        "\n",
        "print(train_data_mean)\n",
        "print(train_data_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 5215\n",
            "    Root location: drive/My Drive/Resize_train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
            "               ToTensor()\n",
            "           )\n",
            "tensor([0.5000, 0.5000, 0.5000])\n",
            "tensor([0.5000, 0.5000, 0.5000])\n",
            "tensor([0.5000, 0.5000, 0.5000])\n",
            "tensor([0.5000, 0.5000, 0.5000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KoKfJXYBr2i"
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((300,300)),                      \n",
        "    transforms.CenterCrop(size=224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_data_mean, train_data_std)                                  \n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([ \n",
        "    transforms.Resize((300,300)),                      \n",
        "    transforms.CenterCrop(size=224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_data_mean,train_data_std)                                  \n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(root='drive/My Drive/Resize_train', transform=transform_train)\n",
        "trainloader=torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.ImageFolder(root='drive/My Drive/Resize_test', transform=transform_test)\n",
        "testloader=torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=4)\n",
        "\n",
        "classes = ('NORMAL', 'PNEUMONIA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aldcQr2GRQm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KtKOhK2TYD0"
      },
      "source": [
        "---------------------- Resnet-50 ----------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x--bdpYGBrrt"
      },
      "source": [
        "import torchvision.models.resnet as resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTB0HYT7B2ln"
      },
      "source": [
        "conv1x1 = resnet.conv1x1\n",
        "Bottleneck = resnet.Bottleneck\n",
        "BasicBlock = resnet.BasicBlock"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5lHzJmB9PA"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False, groups=1, width_per_group=64, replace_stride_with_dilation=None, norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \" \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "#        self.inplanes = 64\n",
        "#        self.layer1 = self._make_layer(Bottleneck, 64, 3)\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "\n",
        "        downsample = None\n",
        "\n",
        "        previous_dilation = self.dilation\n",
        "\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion: # 64 != 256 {64 * 4(Bottleneck의 expansion)} \n",
        "\n",
        "        # downsample은 size가 다를 때 사용할 수 있다, 여기서는 channal을 맞추기 위해 사용한다\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),  # conv1x1(64, 64 * 4, stride = 1)\n",
        "                norm_layer(planes * block.expansion), # nrom_layer(64 * 4)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer)) # 레이어에 첫번째 저장\n",
        "        # layers.append(Bottleneck(64, 64, stride = 1, downsample, self.groups, self.base_width, previous_dilation, norm_layer))\n",
        "\n",
        "        self.inplanes = planes * block.expansion # self.inplanes = 64 * 4 = 256\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "        # layer1의 경우 for _ in range(1, 3): // 2번실행\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)  # 순차적으로 진행하는 함수?\n",
        "\n",
        "#  return되는 layers의 값 \n",
        "#  self.layer1 =[\n",
        "#  Bottleneck(64, 64, stride = 1, downsample, self.groups, self.base_width, previous_dilation, norm_layer)\n",
        "#  Bottleneck(256, 64, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer)\n",
        "#  Bottleneck(256, 64, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer)\n",
        "#  ]\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXXpb8ZuB9zj"
      },
      "source": [
        "resnet50 = ResNet(resnet.Bottleneck, [3, 4, 6, 3], 10, True).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBgo7Hc1Tjhk"
      },
      "source": [
        "---------------------- end ----------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffxPCiMwB_D-",
        "outputId": "3b97120e-ad99-469c-a8d4-86c854bffd44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 동작확인\n",
        "a=torch.Tensor(1,3,224,224).to(device)\n",
        "out = resnet50(a)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3410,  0.0053, -0.0515,  0.0178, -0.0672, -0.0869,  0.0526,  0.1925,\n",
            "          0.2404, -0.4926]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1UMaTOFCARe"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(resnet50.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n",
        "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd93RK1bCCoX"
      },
      "source": [
        "def test_acc_check(net, test_set, epoch, save=1):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in test_set:\n",
        "      images, labels = data\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = net(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  test_acc = (100 * correct / total)\n",
        "  print('Accuracy of the network on the 624 test images: %d %%' % test_acc)\n",
        "#  if save:\n",
        "#    torch.save(net.state_dict(). \".drive/My Drive/study/model/model_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
        "#  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTg7kiG_hq1N"
      },
      "source": [
        "def train_acc_check(net, train_set, epoch, save=1):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in train_set:\n",
        "      images, labels = data\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = net(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  train_acc = (100 * correct / total)\n",
        "  print('Accuracy of the network on the 5,216 train images: %d %%' % train_acc)\n",
        "#  if save:\n",
        "#    torch.save(net.state_dict(). \".drive/My Drive/study/model/model_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
        "#  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBdsyMlZCDMW",
        "outputId": "7f5f612a-429b-41aa-f3f8-24b57ab6a372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(trainloader))\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #optimizer.step() 파이썬 업데이트로 lr_sche.step() 이전에 optimizer.step()가 선언되어야한다고 오류떠서 앞으로 놔뒀더니 오류x\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    outputs = resnet50(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 30 == 29:\n",
        "#        value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader) ]))\n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 30))\n",
        "        running_loss = 0.0\n",
        "\n",
        "  lr_sche.step()\n",
        "  train_acc = train_acc_check(resnet50, trainloader, epoch, save=1)\n",
        "  test_acc = test_acc_check(resnet50, testloader, epoch, save=1)\n",
        "#  value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "326\n",
            "[1,    30] loss: 0.063\n",
            "[1,    60] loss: 0.042\n",
            "[1,    90] loss: 0.042\n",
            "[1,   120] loss: 0.036\n",
            "[1,   150] loss: 0.061\n",
            "[1,   180] loss: 0.044\n",
            "[1,   210] loss: 0.087\n",
            "[1,   240] loss: 0.065\n",
            "[1,   270] loss: 0.041\n",
            "[1,   300] loss: 0.055\n",
            "Accuracy of the network on the 5,216 train images: 98 %\n",
            "Accuracy of the network on the 624 test images: 70 %\n",
            "[2,    30] loss: 0.030\n",
            "[2,    60] loss: 0.036\n",
            "[2,    90] loss: 0.032\n",
            "[2,   120] loss: 0.032\n",
            "[2,   150] loss: 0.031\n",
            "[2,   180] loss: 0.036\n",
            "[2,   210] loss: 0.027\n",
            "[2,   240] loss: 0.053\n",
            "[2,   270] loss: 0.024\n",
            "[2,   300] loss: 0.039\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 71 %\n",
            "[3,    30] loss: 0.011\n",
            "[3,    60] loss: 0.017\n",
            "[3,    90] loss: 0.026\n",
            "[3,   120] loss: 0.042\n",
            "[3,   150] loss: 0.014\n",
            "[3,   180] loss: 0.024\n",
            "[3,   210] loss: 0.028\n",
            "[3,   240] loss: 0.014\n",
            "[3,   270] loss: 0.030\n",
            "[3,   300] loss: 0.020\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 71 %\n",
            "[4,    30] loss: 0.016\n",
            "[4,    60] loss: 0.010\n",
            "[4,    90] loss: 0.025\n",
            "[4,   120] loss: 0.012\n",
            "[4,   150] loss: 0.014\n",
            "[4,   180] loss: 0.041\n",
            "[4,   210] loss: 0.039\n",
            "[4,   240] loss: 0.017\n",
            "[4,   270] loss: 0.035\n",
            "[4,   300] loss: 0.029\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 70 %\n",
            "[5,    30] loss: 0.009\n",
            "[5,    60] loss: 0.019\n",
            "[5,    90] loss: 0.017\n",
            "[5,   120] loss: 0.013\n",
            "[5,   150] loss: 0.011\n",
            "[5,   180] loss: 0.028\n",
            "[5,   210] loss: 0.018\n",
            "[5,   240] loss: 0.006\n",
            "[5,   270] loss: 0.016\n",
            "[5,   300] loss: 0.021\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 72 %\n",
            "[6,    30] loss: 0.019\n",
            "[6,    60] loss: 0.010\n",
            "[6,    90] loss: 0.011\n",
            "[6,   120] loss: 0.011\n",
            "[6,   150] loss: 0.014\n",
            "[6,   180] loss: 0.019\n",
            "[6,   210] loss: 0.013\n",
            "[6,   240] loss: 0.009\n",
            "[6,   270] loss: 0.014\n",
            "[6,   300] loss: 0.009\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 70 %\n",
            "[7,    30] loss: 0.006\n",
            "[7,    60] loss: 0.011\n",
            "[7,    90] loss: 0.007\n",
            "[7,   120] loss: 0.006\n",
            "[7,   150] loss: 0.013\n",
            "[7,   180] loss: 0.009\n",
            "[7,   210] loss: 0.005\n",
            "[7,   240] loss: 0.014\n",
            "[7,   270] loss: 0.019\n",
            "[7,   300] loss: 0.008\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 70 %\n",
            "[8,    30] loss: 0.007\n",
            "[8,    60] loss: 0.005\n",
            "[8,    90] loss: 0.010\n",
            "[8,   120] loss: 0.007\n",
            "[8,   150] loss: 0.006\n",
            "[8,   180] loss: 0.009\n",
            "[8,   210] loss: 0.012\n",
            "[8,   240] loss: 0.010\n",
            "[8,   270] loss: 0.005\n",
            "[8,   300] loss: 0.008\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 72 %\n",
            "[9,    30] loss: 0.018\n",
            "[9,    60] loss: 0.016\n",
            "[9,    90] loss: 0.005\n",
            "[9,   120] loss: 0.009\n",
            "[9,   150] loss: 0.009\n",
            "[9,   180] loss: 0.012\n",
            "[9,   210] loss: 0.010\n",
            "[9,   240] loss: 0.011\n",
            "[9,   270] loss: 0.009\n",
            "[9,   300] loss: 0.010\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 70 %\n",
            "[10,    30] loss: 0.010\n",
            "[10,    60] loss: 0.011\n",
            "[10,    90] loss: 0.011\n",
            "[10,   120] loss: 0.004\n",
            "[10,   150] loss: 0.006\n",
            "[10,   180] loss: 0.009\n",
            "[10,   210] loss: 0.004\n",
            "[10,   240] loss: 0.005\n",
            "[10,   270] loss: 0.004\n",
            "[10,   300] loss: 0.015\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 70 %\n",
            "[11,    30] loss: 0.007\n",
            "[11,    60] loss: 0.004\n",
            "[11,    90] loss: 0.006\n",
            "[11,   120] loss: 0.004\n",
            "[11,   150] loss: 0.005\n",
            "[11,   180] loss: 0.004\n",
            "[11,   210] loss: 0.006\n",
            "[11,   240] loss: 0.004\n",
            "[11,   270] loss: 0.003\n",
            "[11,   300] loss: 0.003\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 72 %\n",
            "[12,    30] loss: 0.004\n",
            "[12,    60] loss: 0.003\n",
            "[12,    90] loss: 0.003\n",
            "[12,   120] loss: 0.002\n",
            "[12,   150] loss: 0.004\n",
            "[12,   180] loss: 0.004\n",
            "[12,   210] loss: 0.004\n",
            "[12,   240] loss: 0.003\n",
            "[12,   270] loss: 0.002\n",
            "[12,   300] loss: 0.004\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 73 %\n",
            "[13,    30] loss: 0.001\n",
            "[13,    60] loss: 0.001\n",
            "[13,    90] loss: 0.002\n",
            "[13,   120] loss: 0.003\n",
            "[13,   150] loss: 0.002\n",
            "[13,   180] loss: 0.002\n",
            "[13,   210] loss: 0.002\n",
            "[13,   240] loss: 0.004\n",
            "[13,   270] loss: 0.003\n",
            "[13,   300] loss: 0.002\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 73 %\n",
            "[14,    30] loss: 0.001\n",
            "[14,    60] loss: 0.001\n",
            "[14,    90] loss: 0.003\n",
            "[14,   120] loss: 0.003\n",
            "[14,   150] loss: 0.001\n",
            "[14,   180] loss: 0.001\n",
            "[14,   210] loss: 0.001\n",
            "[14,   240] loss: 0.002\n",
            "[14,   270] loss: 0.001\n",
            "[14,   300] loss: 0.003\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[15,    30] loss: 0.001\n",
            "[15,    60] loss: 0.001\n",
            "[15,    90] loss: 0.002\n",
            "[15,   120] loss: 0.002\n",
            "[15,   150] loss: 0.001\n",
            "[15,   180] loss: 0.005\n",
            "[15,   210] loss: 0.004\n",
            "[15,   240] loss: 0.001\n",
            "[15,   270] loss: 0.001\n",
            "[15,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 73 %\n",
            "[16,    30] loss: 0.003\n",
            "[16,    60] loss: 0.004\n",
            "[16,    90] loss: 0.003\n",
            "[16,   120] loss: 0.002\n",
            "[16,   150] loss: 0.001\n",
            "[16,   180] loss: 0.002\n",
            "[16,   210] loss: 0.002\n",
            "[16,   240] loss: 0.002\n",
            "[16,   270] loss: 0.002\n",
            "[16,   300] loss: 0.003\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 72 %\n",
            "[17,    30] loss: 0.002\n",
            "[17,    60] loss: 0.001\n",
            "[17,    90] loss: 0.004\n",
            "[17,   120] loss: 0.002\n",
            "[17,   150] loss: 0.002\n",
            "[17,   180] loss: 0.001\n",
            "[17,   210] loss: 0.003\n",
            "[17,   240] loss: 0.002\n",
            "[17,   270] loss: 0.001\n",
            "[17,   300] loss: 0.002\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 73 %\n",
            "[18,    30] loss: 0.002\n",
            "[18,    60] loss: 0.002\n",
            "[18,    90] loss: 0.002\n",
            "[18,   120] loss: 0.002\n",
            "[18,   150] loss: 0.001\n",
            "[18,   180] loss: 0.002\n",
            "[18,   210] loss: 0.001\n",
            "[18,   240] loss: 0.003\n",
            "[18,   270] loss: 0.001\n",
            "[18,   300] loss: 0.003\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 72 %\n",
            "[19,    30] loss: 0.002\n",
            "[19,    60] loss: 0.001\n",
            "[19,    90] loss: 0.001\n",
            "[19,   120] loss: 0.002\n",
            "[19,   150] loss: 0.002\n",
            "[19,   180] loss: 0.002\n",
            "[19,   210] loss: 0.001\n",
            "[19,   240] loss: 0.001\n",
            "[19,   270] loss: 0.001\n",
            "[19,   300] loss: 0.002\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 73 %\n",
            "[20,    30] loss: 0.001\n",
            "[20,    60] loss: 0.001\n",
            "[20,    90] loss: 0.001\n",
            "[20,   120] loss: 0.002\n",
            "[20,   150] loss: 0.007\n",
            "[20,   180] loss: 0.004\n",
            "[20,   210] loss: 0.001\n",
            "[20,   240] loss: 0.002\n",
            "[20,   270] loss: 0.001\n",
            "[20,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[21,    30] loss: 0.001\n",
            "[21,    60] loss: 0.001\n",
            "[21,    90] loss: 0.001\n",
            "[21,   120] loss: 0.001\n",
            "[21,   150] loss: 0.001\n",
            "[21,   180] loss: 0.001\n",
            "[21,   210] loss: 0.001\n",
            "[21,   240] loss: 0.001\n",
            "[21,   270] loss: 0.001\n",
            "[21,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[22,    30] loss: 0.002\n",
            "[22,    60] loss: 0.001\n",
            "[22,    90] loss: 0.001\n",
            "[22,   120] loss: 0.001\n",
            "[22,   150] loss: 0.001\n",
            "[22,   180] loss: 0.001\n",
            "[22,   210] loss: 0.002\n",
            "[22,   240] loss: 0.008\n",
            "[22,   270] loss: 0.001\n",
            "[22,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[23,    30] loss: 0.001\n",
            "[23,    60] loss: 0.002\n",
            "[23,    90] loss: 0.001\n",
            "[23,   120] loss: 0.001\n",
            "[23,   150] loss: 0.001\n",
            "[23,   180] loss: 0.007\n",
            "[23,   210] loss: 0.003\n",
            "[23,   240] loss: 0.001\n",
            "[23,   270] loss: 0.002\n",
            "[23,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 73 %\n",
            "[24,    30] loss: 0.001\n",
            "[24,    60] loss: 0.001\n",
            "[24,    90] loss: 0.002\n",
            "[24,   120] loss: 0.001\n",
            "[24,   150] loss: 0.001\n",
            "[24,   180] loss: 0.011\n",
            "[24,   210] loss: 0.001\n",
            "[24,   240] loss: 0.002\n",
            "[24,   270] loss: 0.001\n",
            "[24,   300] loss: 0.002\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[25,    30] loss: 0.002\n",
            "[25,    60] loss: 0.001\n",
            "[25,    90] loss: 0.002\n",
            "[25,   120] loss: 0.001\n",
            "[25,   150] loss: 0.001\n",
            "[25,   180] loss: 0.001\n",
            "[25,   210] loss: 0.002\n",
            "[25,   240] loss: 0.001\n",
            "[25,   270] loss: 0.002\n",
            "[25,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[26,    30] loss: 0.001\n",
            "[26,    60] loss: 0.001\n",
            "[26,    90] loss: 0.001\n",
            "[26,   120] loss: 0.001\n",
            "[26,   150] loss: 0.001\n",
            "[26,   180] loss: 0.001\n",
            "[26,   210] loss: 0.001\n",
            "[26,   240] loss: 0.001\n",
            "[26,   270] loss: 0.002\n",
            "[26,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[27,    30] loss: 0.001\n",
            "[27,    60] loss: 0.001\n",
            "[27,    90] loss: 0.010\n",
            "[27,   120] loss: 0.002\n",
            "[27,   150] loss: 0.002\n",
            "[27,   180] loss: 0.001\n",
            "[27,   210] loss: 0.001\n",
            "[27,   240] loss: 0.001\n",
            "[27,   270] loss: 0.001\n",
            "[27,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[28,    30] loss: 0.001\n",
            "[28,    60] loss: 0.001\n",
            "[28,    90] loss: 0.001\n",
            "[28,   120] loss: 0.001\n",
            "[28,   150] loss: 0.001\n",
            "[28,   180] loss: 0.001\n",
            "[28,   210] loss: 0.001\n",
            "[28,   240] loss: 0.001\n",
            "[28,   270] loss: 0.002\n",
            "[28,   300] loss: 0.002\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[29,    30] loss: 0.001\n",
            "[29,    60] loss: 0.001\n",
            "[29,    90] loss: 0.001\n",
            "[29,   120] loss: 0.001\n",
            "[29,   150] loss: 0.001\n",
            "[29,   180] loss: 0.001\n",
            "[29,   210] loss: 0.001\n",
            "[29,   240] loss: 0.002\n",
            "[29,   270] loss: 0.001\n",
            "[29,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[30,    30] loss: 0.001\n",
            "[30,    60] loss: 0.001\n",
            "[30,    90] loss: 0.001\n",
            "[30,   120] loss: 0.001\n",
            "[30,   150] loss: 0.001\n",
            "[30,   180] loss: 0.001\n",
            "[30,   210] loss: 0.001\n",
            "[30,   240] loss: 0.001\n",
            "[30,   270] loss: 0.001\n",
            "[30,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[31,    30] loss: 0.001\n",
            "[31,    60] loss: 0.003\n",
            "[31,    90] loss: 0.001\n",
            "[31,   120] loss: 0.001\n",
            "[31,   150] loss: 0.002\n",
            "[31,   180] loss: 0.001\n",
            "[31,   210] loss: 0.001\n",
            "[31,   240] loss: 0.002\n",
            "[31,   270] loss: 0.002\n",
            "[31,   300] loss: 0.002\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[32,    30] loss: 0.001\n",
            "[32,    60] loss: 0.001\n",
            "[32,    90] loss: 0.001\n",
            "[32,   120] loss: 0.001\n",
            "[32,   150] loss: 0.001\n",
            "[32,   180] loss: 0.001\n",
            "[32,   210] loss: 0.001\n",
            "[32,   240] loss: 0.001\n",
            "[32,   270] loss: 0.001\n",
            "[32,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[33,    30] loss: 0.001\n",
            "[33,    60] loss: 0.009\n",
            "[33,    90] loss: 0.001\n",
            "[33,   120] loss: 0.001\n",
            "[33,   150] loss: 0.001\n",
            "[33,   180] loss: 0.001\n",
            "[33,   210] loss: 0.001\n",
            "[33,   240] loss: 0.001\n",
            "[33,   270] loss: 0.001\n",
            "[33,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[34,    30] loss: 0.001\n",
            "[34,    60] loss: 0.001\n",
            "[34,    90] loss: 0.001\n",
            "[34,   120] loss: 0.001\n",
            "[34,   150] loss: 0.002\n",
            "[34,   180] loss: 0.001\n",
            "[34,   210] loss: 0.001\n",
            "[34,   240] loss: 0.001\n",
            "[34,   270] loss: 0.001\n",
            "[34,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[35,    30] loss: 0.001\n",
            "[35,    60] loss: 0.001\n",
            "[35,    90] loss: 0.001\n",
            "[35,   120] loss: 0.001\n",
            "[35,   150] loss: 0.001\n",
            "[35,   180] loss: 0.001\n",
            "[35,   210] loss: 0.001\n",
            "[35,   240] loss: 0.001\n",
            "[35,   270] loss: 0.001\n",
            "[35,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[36,    30] loss: 0.001\n",
            "[36,    60] loss: 0.001\n",
            "[36,    90] loss: 0.001\n",
            "[36,   120] loss: 0.001\n",
            "[36,   150] loss: 0.001\n",
            "[36,   180] loss: 0.002\n",
            "[36,   210] loss: 0.002\n",
            "[36,   240] loss: 0.001\n",
            "[36,   270] loss: 0.001\n",
            "[36,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[37,    30] loss: 0.001\n",
            "[37,    60] loss: 0.003\n",
            "[37,    90] loss: 0.001\n",
            "[37,   120] loss: 0.001\n",
            "[37,   150] loss: 0.001\n",
            "[37,   180] loss: 0.000\n",
            "[37,   210] loss: 0.001\n",
            "[37,   240] loss: 0.003\n",
            "[37,   270] loss: 0.002\n",
            "[37,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[38,    30] loss: 0.002\n",
            "[38,    60] loss: 0.001\n",
            "[38,    90] loss: 0.001\n",
            "[38,   120] loss: 0.001\n",
            "[38,   150] loss: 0.001\n",
            "[38,   180] loss: 0.001\n",
            "[38,   210] loss: 0.001\n",
            "[38,   240] loss: 0.001\n",
            "[38,   270] loss: 0.001\n",
            "[38,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[39,    30] loss: 0.001\n",
            "[39,    60] loss: 0.001\n",
            "[39,    90] loss: 0.003\n",
            "[39,   120] loss: 0.001\n",
            "[39,   150] loss: 0.003\n",
            "[39,   180] loss: 0.003\n",
            "[39,   210] loss: 0.001\n",
            "[39,   240] loss: 0.001\n",
            "[39,   270] loss: 0.001\n",
            "[39,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[40,    30] loss: 0.002\n",
            "[40,    60] loss: 0.001\n",
            "[40,    90] loss: 0.001\n",
            "[40,   120] loss: 0.001\n",
            "[40,   150] loss: 0.001\n",
            "[40,   180] loss: 0.001\n",
            "[40,   210] loss: 0.001\n",
            "[40,   240] loss: 0.001\n",
            "[40,   270] loss: 0.003\n",
            "[40,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[41,    30] loss: 0.001\n",
            "[41,    60] loss: 0.001\n",
            "[41,    90] loss: 0.001\n",
            "[41,   120] loss: 0.001\n",
            "[41,   150] loss: 0.001\n",
            "[41,   180] loss: 0.001\n",
            "[41,   210] loss: 0.001\n",
            "[41,   240] loss: 0.001\n",
            "[41,   270] loss: 0.001\n",
            "[41,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[42,    30] loss: 0.001\n",
            "[42,    60] loss: 0.003\n",
            "[42,    90] loss: 0.001\n",
            "[42,   120] loss: 0.001\n",
            "[42,   150] loss: 0.001\n",
            "[42,   180] loss: 0.001\n",
            "[42,   210] loss: 0.001\n",
            "[42,   240] loss: 0.002\n",
            "[42,   270] loss: 0.001\n",
            "[42,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[43,    30] loss: 0.001\n",
            "[43,    60] loss: 0.001\n",
            "[43,    90] loss: 0.001\n",
            "[43,   120] loss: 0.001\n",
            "[43,   150] loss: 0.001\n",
            "[43,   180] loss: 0.000\n",
            "[43,   210] loss: 0.001\n",
            "[43,   240] loss: 0.001\n",
            "[43,   270] loss: 0.000\n",
            "[43,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[44,    30] loss: 0.001\n",
            "[44,    60] loss: 0.001\n",
            "[44,    90] loss: 0.002\n",
            "[44,   120] loss: 0.001\n",
            "[44,   150] loss: 0.001\n",
            "[44,   180] loss: 0.001\n",
            "[44,   210] loss: 0.001\n",
            "[44,   240] loss: 0.001\n",
            "[44,   270] loss: 0.001\n",
            "[44,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 99 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[45,    30] loss: 0.001\n",
            "[45,    60] loss: 0.001\n",
            "[45,    90] loss: 0.001\n",
            "[45,   120] loss: 0.001\n",
            "[45,   150] loss: 0.000\n",
            "[45,   180] loss: 0.000\n",
            "[45,   210] loss: 0.001\n",
            "[45,   240] loss: 0.000\n",
            "[45,   270] loss: 0.001\n",
            "[45,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[46,    30] loss: 0.001\n",
            "[46,    60] loss: 0.001\n",
            "[46,    90] loss: 0.001\n",
            "[46,   120] loss: 0.001\n",
            "[46,   150] loss: 0.001\n",
            "[46,   180] loss: 0.004\n",
            "[46,   210] loss: 0.001\n",
            "[46,   240] loss: 0.001\n",
            "[46,   270] loss: 0.001\n",
            "[46,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[47,    30] loss: 0.001\n",
            "[47,    60] loss: 0.001\n",
            "[47,    90] loss: 0.001\n",
            "[47,   120] loss: 0.001\n",
            "[47,   150] loss: 0.001\n",
            "[47,   180] loss: 0.001\n",
            "[47,   210] loss: 0.001\n",
            "[47,   240] loss: 0.001\n",
            "[47,   270] loss: 0.001\n",
            "[47,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[48,    30] loss: 0.001\n",
            "[48,    60] loss: 0.001\n",
            "[48,    90] loss: 0.001\n",
            "[48,   120] loss: 0.001\n",
            "[48,   150] loss: 0.001\n",
            "[48,   180] loss: 0.001\n",
            "[48,   210] loss: 0.001\n",
            "[48,   240] loss: 0.001\n",
            "[48,   270] loss: 0.000\n",
            "[48,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 75 %\n",
            "[49,    30] loss: 0.001\n",
            "[49,    60] loss: 0.001\n",
            "[49,    90] loss: 0.004\n",
            "[49,   120] loss: 0.001\n",
            "[49,   150] loss: 0.001\n",
            "[49,   180] loss: 0.000\n",
            "[49,   210] loss: 0.002\n",
            "[49,   240] loss: 0.001\n",
            "[49,   270] loss: 0.001\n",
            "[49,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "[50,    30] loss: 0.001\n",
            "[50,    60] loss: 0.002\n",
            "[50,    90] loss: 0.001\n",
            "[50,   120] loss: 0.001\n",
            "[50,   150] loss: 0.001\n",
            "[50,   180] loss: 0.001\n",
            "[50,   210] loss: 0.001\n",
            "[50,   240] loss: 0.001\n",
            "[50,   270] loss: 0.002\n",
            "[50,   300] loss: 0.001\n",
            "Accuracy of the network on the 5,216 train images: 100 %\n",
            "Accuracy of the network on the 624 test images: 74 %\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2IeCNpNCGJr",
        "outputId": "f7e6a273-29ec-4b4e-d9fb-d0a3a84b3a7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "     images, labels = data\n",
        "     images = images.to(device)\n",
        "     labels = labels.to(device)\n",
        "     outputs = resnet50(images)\n",
        "\n",
        "     _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "     total += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 624 test images: %d %%' %(\n",
        "  100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 624 test images: 0 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}